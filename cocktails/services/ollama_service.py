"""
Service IA utilisant Ollama avec Llama 3.1 et LangGraph pour la g√©n√©ration de cocktails
"""

import logging
import json
import random
from typing import Dict, Any, Optional
from datetime import datetime
from pydantic import BaseModel, Field
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph, END

from cocktails.services.base_ai_service import BaseAIService
from cocktails.models import CocktailRecipe

logger = logging.getLogger(__name__)


# √âtat du workflow de g√©n√©ration de cocktail
class CocktailState(BaseModel):
    user_prompt: str = Field(description="Demande originale de l'utilisateur")
    context: str = Field(default="", description="Contexte additionnel")
    cocktail_type: Optional[str] = None
    base_spirits: Optional[list] = None
    flavor_profile: Optional[str] = None
    cocktail_concept: Optional[Dict] = None
    ingredients: Optional[list] = None
    instructions: Optional[str] = None
    final_cocktail: Optional[Dict] = None
    image_prompt: Optional[str] = None


# Mod√®les Pydantic pour les √©tapes du workflow
class CocktailType(BaseModel):
    type: str = Field(description="Type de cocktail: 'alcoolis√©', 'sans alcool', 'digestif', 'ap√©ritif'")
    occasion: str = Field(description="Occasion: 'soir√©e', 'd√©jeuner', 'f√™te', 'd√©tente'")

class BaseSpirits(BaseModel):
    spirits: list[str] = Field(description="Liste des alcools de base recommand√©s")
    reasoning: str = Field(description="Explication du choix")

class FlavorProfile(BaseModel):
    profile: str = Field(description="Profil de saveur: 'fruit√©', '√©pic√©', 'frais', 'sucr√©', 'amer'")
    intensity: str = Field(description="Intensit√©: 'l√©ger', 'moyen', 'intense'")

class CocktailConcept(BaseModel):
    name: str = Field(description="Nom cr√©atif du cocktail")
    description: str = Field(description="Description narrative du cocktail")
    theme: str = Field(description="Th√®me ou inspiration du cocktail")

class Ingredient(BaseModel):
    nom: str = Field(description="Nom de l'ingr√©dient")
    quantite: str = Field(description="Quantit√© avec unit√© SI obligatoire (ex: '50 ml', '10 g', '2 pinc√©es')")
    type: str = Field(description="Type: 'alcool', 'mixer', 'garniture', '√©pice', 'autre'")

class CocktailIngredients(BaseModel):
    ingredients: list[Ingredient] = Field(
        description="Liste d√©taill√©e des ingr√©dients avec quantit√©s en unit√©s SI (ml pour liquides, g pour solides)"
    )

class CocktailInstructions(BaseModel):
    instructions: str = Field(description="Instructions de pr√©paration √©tape par √©tape")
    glass_type: str = Field(description="Type de verre recommand√©")
    garnish: str = Field(description="Garniture et d√©coration")
    difficulty: str = Field(description="Niveau de difficult√©")

class ImagePrompt(BaseModel):
    prompt: str = Field(description="Prompt pour g√©n√©rer l'image du cocktail")


class OllamaService(BaseAIService):
    """Service IA utilisant Ollama avec Llama 3.1 et workflow LangGraph"""
    
    def __init__(self):
        super().__init__()
        try:
            self.llm = ChatOllama(model="llama3.1")
            logger.info("ü¶ô Service Ollama configur√© avec Llama 3.1")
            self._test_connection()
            self._build_cocktail_workflow()
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'initialisation d'Ollama: {e}")
            raise
    
    def _test_connection(self):
        """Test la connexion √† Ollama"""
        try:
            test_response = self.llm.invoke("Dis bonjour")
            logger.info("‚úÖ Connexion Ollama OK")
        except Exception as e:
            logger.error(f"‚ùå Impossible de se connecter √† Ollama: {e}")
            raise Exception("Ollama n'est pas disponible. Assurez-vous qu'Ollama est d√©marr√© avec: ollama serve")
    
    def _build_cocktail_workflow(self):
        """Construit le workflow LangGraph pour la g√©n√©ration de cocktails"""
        
        # Cr√©er le graphe d'√©tat
        graph = StateGraph(CocktailState)
        
        # Ajouter les n≈ìuds du workflow
        graph.add_node("analyze_request", self._analyze_request)
        graph.add_node("determine_base_spirits", self._determine_base_spirits)
        graph.add_node("define_flavor_profile", self._define_flavor_profile)
        graph.add_node("create_concept", self._create_concept)
        graph.add_node("generate_ingredients", self._generate_ingredients)
        graph.add_node("write_instructions", self._write_instructions)
        graph.add_node("finalize_cocktail", self._finalize_cocktail)
        graph.add_node("generate_image_prompt", self._generate_image_prompt_node)
        
        # D√©finir le point d'entr√©e
        graph.set_entry_point("analyze_request")
        
        # D√©finir les transitions
        graph.add_edge("analyze_request", "determine_base_spirits")
        graph.add_edge("determine_base_spirits", "define_flavor_profile")
        graph.add_edge("define_flavor_profile", "create_concept")
        graph.add_edge("create_concept", "generate_ingredients")
        graph.add_edge("generate_ingredients", "write_instructions")
        graph.add_edge("write_instructions", "finalize_cocktail")
        graph.add_edge("finalize_cocktail", "generate_image_prompt")
        graph.add_edge("generate_image_prompt", END)
        
        # Compiler le workflow
        self.cocktail_graph = graph.compile()
        logger.info("üîÑ Workflow LangGraph de g√©n√©ration de cocktails initialis√©")
    
    def generate_cocktail(self, user_prompt: str, context: str = "") -> Dict[str, Any]:
        """G√©n√®re un cocktail en utilisant le workflow LangGraph"""
        logger.info(f"ü¶ô G√©n√©ration IA avec workflow LangGraph pour: '{user_prompt}'")
        
        # √âtat initial
        initial_state = CocktailState(
            user_prompt=user_prompt,
            context=context or "Cr√©ation libre"
        )
        
        try:
            # Ex√©cuter le workflow
            final_state = self.cocktail_graph.invoke(initial_state)
            
            # R√©cup√©rer le r√©sultat final
            cocktail_data = final_state["final_cocktail"]
            cocktail_data['image_prompt'] = final_state["image_prompt"]
            
            # Ajouter une image placeholder
            cocktail_data['image_url'] = self._generate_placeholder_image()
            
            logger.info(f"‚úÖ Cocktail g√©n√©r√© via workflow: {cocktail_data['name']}")
            return cocktail_data
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration cocktail workflow: {e}")
            raise Exception(f"Impossible de g√©n√©rer le cocktail: {e}")
    
    # ============================================================================
    # √âTAPES DU WORKFLOW LANGGRAPH
    # ============================================================================
    
    def _analyze_request(self, state: CocktailState) -> CocktailState:
        """√âtape 1: Analyser la demande de l'utilisateur"""
        logger.info("üîç √âtape 1: Analyse de la demande")
        
        prompt = ChatPromptTemplate.from_template("""
        Analyse cette demande de cocktail et d√©termine le type et l'occasion.
        
        Demande: {user_prompt}
        Contexte: {context}
        
        D√©termine:
        - Le type de cocktail souhait√©
        - L'occasion ou le moment de consommation
        """)
        
        structured_llm = self.llm.with_structured_output(CocktailType)
        chain = prompt | structured_llm
        
        result = chain.invoke({
            "user_prompt": state.user_prompt,
            "context": state.context
        })
        
        state.cocktail_type = result.type
        logger.info(f"   ‚Üí Type d√©tect√©: {result.type}, Occasion: {result.occasion}")
        return state
    
    def _determine_base_spirits(self, state: CocktailState) -> CocktailState:
        """√âtape 2: D√©terminer les alcools de base"""
        logger.info("üç∫ √âtape 2: S√©lection des alcools de base")
        
        prompt = ChatPromptTemplate.from_template("""
        Bas√© sur cette demande, recommande les meilleurs alcools de base.
        
        Demande: {user_prompt}
        Type de cocktail: {cocktail_type}
        Contexte: {context}
        
        Recommande 1-3 alcools de base appropri√©s et explique pourquoi.
        """)
        
        structured_llm = self.llm.with_structured_output(BaseSpirits)
        chain = prompt | structured_llm
        
        result = chain.invoke({
            "user_prompt": state.user_prompt,
            "cocktail_type": state.cocktail_type,
            "context": state.context
        })
        
        state.base_spirits = result.spirits
        logger.info(f"   ‚Üí Alcools s√©lectionn√©s: {', '.join(result.spirits)}")
        return state
    
    def _define_flavor_profile(self, state: CocktailState) -> CocktailState:
        """√âtape 3: D√©finir le profil de saveur"""
        logger.info("üëÖ √âtape 3: D√©finition du profil de saveur")
        
        prompt = ChatPromptTemplate.from_template("""
        D√©finis le profil de saveur pour ce cocktail.
        
        Demande: {user_prompt}
        Alcools de base: {base_spirits}
        Type: {cocktail_type}
        
        D√©termine le profil de saveur et son intensit√©.
        """)
        
        structured_llm = self.llm.with_structured_output(FlavorProfile)
        chain = prompt | structured_llm
        
        result = chain.invoke({
            "user_prompt": state.user_prompt,
            "base_spirits": state.base_spirits,
            "cocktail_type": state.cocktail_type
        })
        
        state.flavor_profile = result.profile
        logger.info(f"   ‚Üí Profil: {result.profile} ({result.intensity})")
        return state
    
    def _create_concept(self, state: CocktailState) -> CocktailState:
        """√âtape 4: Cr√©er le concept du cocktail"""
        logger.info("üí° √âtape 4: Cr√©ation du concept")
        
        prompt = ChatPromptTemplate.from_template("""
        Cr√©e un concept cr√©atif pour ce cocktail.
        
        Demande: {user_prompt}
        Alcools: {base_spirits}
        Profil de saveur: {flavor_profile}
        Type: {cocktail_type}
        
        Invente un nom cr√©atif, une description narrative et un th√®me inspirant.
        """)
        
        structured_llm = self.llm.with_structured_output(CocktailConcept)
        chain = prompt | structured_llm
        
        result = chain.invoke({
            "user_prompt": state.user_prompt,
            "base_spirits": state.base_spirits,
            "flavor_profile": state.flavor_profile,
            "cocktail_type": state.cocktail_type
        })
        
        state.cocktail_concept = {
            "name": result.name,
            "description": result.description,
            "theme": result.theme
        }
        logger.info(f"   ‚Üí Concept: {result.name}")
        return state
    
    def _generate_ingredients(self, state: CocktailState) -> CocktailState:
        """√âtape 5: G√©n√©rer la liste des ingr√©dients"""
        logger.info("üß™ √âtape 5: G√©n√©ration des ingr√©dients")
        
        prompt = ChatPromptTemplate.from_template("""
        Cr√©e la liste pr√©cise des ingr√©dients pour ce cocktail.
        
        Nom: {name}
        Alcools de base: {base_spirits}
        Profil de saveur: {flavor_profile}
        Description: {description}
        
        IMPORTANT: Retourne une liste de dictionnaires avec ce format exact:
        - "nom": nom de l'ingr√©dient
        - "quantite": quantit√© avec unit√© (ex: "50 ml", "2 cl", "1 cuill√®re")
        - "type": type d'ingr√©dient ("alcool", "mixer", "garniture", "√©pice", "autre")
        
        Liste tous les ingr√©dients avec quantit√©s pr√©cises.
        Inclus alcools, mixers, garnitures, √©pices, etc.
        """)
        
        structured_llm = self.llm.with_structured_output(CocktailIngredients)
        chain = prompt | structured_llm
        
        result = chain.invoke({
            "name": state.cocktail_concept["name"],
            "base_spirits": state.base_spirits,
            "flavor_profile": state.flavor_profile,
            "description": state.cocktail_concept["description"]
        })
        
        # Convertir imm√©diatement les ingr√©dients en dictionnaires
        ingredients_list = []
        for ingredient in result.ingredients:
            if hasattr(ingredient, 'dict'):  # Si c'est un objet Pydantic
                ingredients_list.append(ingredient.dict())
            elif hasattr(ingredient, '__dict__'):  # Si c'est un autre type d'objet
                ingredients_list.append(vars(ingredient))
            elif isinstance(ingredient, dict):  # Si c'est d√©j√† un dictionnaire
                ingredients_list.append(ingredient)
            else:  # Autre type, convertir en dict basique
                ingredients_list.append({
                    'nom': str(ingredient), 
                    'quantite': '√Ä doser', 
                    'type': 'autre'
                })
        
        state.ingredients = ingredients_list
        logger.info(f"   ‚Üí {len(ingredients_list)} ingr√©dients g√©n√©r√©s")
        return state
    
    def _write_instructions(self, state: CocktailState) -> CocktailState:
        """√âtape 6: R√©diger les instructions"""
        logger.info("üìù √âtape 6: R√©daction des instructions")
        
        prompt = ChatPromptTemplate.from_template("""
        √âcris les instructions d√©taill√©es pour pr√©parer ce cocktail.
        
        Nom: {name}
        Ingr√©dients: {ingredients}
        Profil: {flavor_profile}
        
        Fournis:
        - Instructions √©tape par √©tape
        - Type de verre recommand√©
        - Garniture et d√©coration
        - Niveau de difficult√©
        """)
        
        structured_llm = self.llm.with_structured_output(CocktailInstructions)
        chain = prompt | structured_llm
        
        result = chain.invoke({
            "name": state.cocktail_concept["name"],
            "ingredients": state.ingredients,
            "flavor_profile": state.flavor_profile
        })
        
        state.instructions = result.instructions
        logger.info(f"   ‚Üí Instructions r√©dig√©es ({result.difficulty})")
        return state
    
    def _finalize_cocktail(self, state: CocktailState) -> CocktailState:
        """√âtape 7: Finaliser le cocktail"""
        logger.info("‚ú® √âtape 7: Finalisation du cocktail")
        
        # Convertir les ingr√©dients en dictionnaires JSON s√©rialisables
        ingredients_list = []
        for ingredient in state.ingredients:
            if hasattr(ingredient, 'dict'):  # Si c'est un objet Pydantic
                ingredients_list.append(ingredient.dict())
            elif isinstance(ingredient, dict):  # Si c'est d√©j√† un dictionnaire
                ingredients_list.append(ingredient)
            else:  # Autre type, convertir en string puis en dict basique
                ingredients_list.append({'nom': str(ingredient), 'quantite': '', 'type': 'autre'})
        
        # Assembler toutes les donn√©es
        final_cocktail = {
            'name': state.cocktail_concept["name"],
            'description': state.cocktail_concept["description"],
            'instructions': state.instructions,
            'ingredients': ingredients_list,  # Utiliser la liste convertie
            'theme': state.cocktail_concept["theme"],
            'flavor_profile': state.flavor_profile,
            'alcohol_content': self._estimate_alcohol_content(ingredients_list),
            'preparation_time': self._estimate_prep_time_from_ingredients(ingredients_list),
            'original_prompt': state.user_prompt,
            'created_at': datetime.now().isoformat(),
            'music_ambiance': f"Ambiance parfaite pour d√©guster le {state.cocktail_concept['name']}"
        }
        
        state.final_cocktail = final_cocktail
        return state
    
    def _generate_image_prompt_node(self, state: CocktailState) -> CocktailState:
        """√âtape 8: G√©n√©rer le prompt d'image"""
        logger.info("üé® √âtape 8: G√©n√©ration du prompt d'image")
        
        prompt = ChatPromptTemplate.from_template("""
        Cr√©e un prompt en anglais pour g√©n√©rer l'image de ce cocktail.
        
        Nom: {name}
        Description: {description}
        Ingr√©dients: {ingredients}
        Th√®me: {theme}
        
        Le prompt doit √™tre descriptif et visuellement √©vocateur pour une IA de g√©n√©ration d'images.
        """)
        
        structured_llm = self.llm.with_structured_output(ImagePrompt)
        chain = prompt | structured_llm
        
        result = chain.invoke({
            "name": state.cocktail_concept["name"],
            "description": state.cocktail_concept["description"],
            "ingredients": str(state.ingredients),
            "theme": state.cocktail_concept["theme"]
        })
        
        state.image_prompt = result.prompt
        logger.info(f"   ‚Üí Prompt d'image g√©n√©r√©")
        return state
    
    # ============================================================================
    # M√âTHODES UTILITAIRES
    # ============================================================================
    
    def _estimate_alcohol_content(self, ingredients: list) -> float:
        """Estime le degr√© d'alcool bas√© sur les ingr√©dients"""
        alcohol_keywords = ['vodka', 'gin', 'rhum', 'whisky', 'tequila', 'cognac', 'liqueur', 'vin', 'champagne']
        
        alcohol_count = 0
        for ing in ingredients:
            ing_name = ing.get('name', '') if isinstance(ing, dict) else str(ing)
            if any(keyword in ing_name.lower() for keyword in alcohol_keywords):
                alcohol_count += 1
        
        if alcohol_count == 0:
            return 0.0
        elif alcohol_count == 1:
            return random.uniform(8.0, 15.0)
        elif alcohol_count == 2:
            return random.uniform(15.0, 25.0)
        else:
            return random.uniform(25.0, 35.0)
    
    def _estimate_prep_time_from_ingredients(self, ingredients: list) -> int:
        """Estime le temps de pr√©paration selon le nombre d'ingr√©dients"""
        ingredient_count = len(ingredients)
        
        if ingredient_count <= 3:
            return random.randint(2, 5)
        elif ingredient_count <= 6:
            return random.randint(5, 10)
        else:
            return random.randint(10, 20)
    
    def generate_image_prompt(self, cocktail_name: str, description: str) -> str:
        """G√©n√®re un prompt d'image (m√©thode de compatibilit√©)"""
        return self._generate_image_prompt_simple(cocktail_name, description)
    
    def _generate_image_prompt_simple(self, cocktail_name: str, description: str) -> str:
        """Version simplifi√©e pour compatibilit√©"""
        try:
            return f"Beautiful {cocktail_name} cocktail, {description[:100]}, professional photography, colorful, appetizing"
        except Exception:
            return f"Beautiful {cocktail_name} cocktail in a glass, professional photography, colorful, appetizing"
    
    def generate_image(self, image_prompt: str) -> Optional[str]:
        """G√©n√®re une image placeholder (Ollama ne fait pas d'images)"""
        logger.info(f"üñºÔ∏è G√©n√©ration d'image placeholder pour: {image_prompt[:50]}...")
        return self._generate_placeholder_image()
    
    def _generate_placeholder_image(self) -> str:
        """G√©n√®re une image placeholder puisque Ollama ne fait pas d'images"""
        placeholder_images = [
            "placeholder_2ed8a5ba.jpg",
            "placeholder_3d0a5333.jpg", 
            "placeholder_401ddb34.jpg",
            "placeholder_5c46358c.jpg",
            "placeholder_9f138c66.jpg",
            "placeholder_ba0d131b.jpg"
        ]
        return f"cocktail_images/{random.choice(placeholder_images)}"
    
    def create_cocktail_recipe(self, cocktail_data: Dict[str, Any], user, generation_request) -> CocktailRecipe:
        """Cr√©e une instance CocktailRecipe Django √† partir des donn√©es IA"""
        try:
            # Adapter les champs au mod√®le Django
            difficulty_mapping = {
                'facile': 'easy',
                'moyen': 'medium', 
                'difficile': 'hard',
                'easy': 'easy',
                'medium': 'medium',
                'hard': 'hard'
            }
            
            # Estimer le niveau d'alcool
            alcohol_level = 'none'
            if cocktail_data.get('alcohol_content', 0) > 0:
                if cocktail_data['alcohol_content'] < 10:
                    alcohol_level = 'low'
                elif cocktail_data['alcohol_content'] < 20:
                    alcohol_level = 'medium'
                else:
                    alcohol_level = 'high'
            
            recipe = CocktailRecipe.objects.create(
                user=user,
                generation_request=generation_request,
                name=cocktail_data['name'],
                description=cocktail_data['description'],
                ingredients=cocktail_data.get('ingredients', []),  # Stock√© en JSON
                music_ambiance=cocktail_data.get('music_ambiance', ''),
                image_prompt=cocktail_data.get('image_prompt', ''),
                image_url=cocktail_data.get('image_url', ''),
                difficulty_level=difficulty_mapping.get(cocktail_data.get('difficulty', 'facile'), 'medium'),
                alcohol_content=alcohol_level,
                preparation_time=cocktail_data.get('preparation_time', 5)
            )
            
            logger.info(f"‚úÖ Cocktail cr√©√© en DB: {recipe.name}")
            return recipe
            
        except Exception as e:
            logger.error(f"‚ùå Erreur cr√©ation DB: {e}")
            raise
